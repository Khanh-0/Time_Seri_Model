
# ğŸ“ˆ Stock Price Forecasting: Linear Family Models

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-150458?logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![Status](https://img.shields.io/badge/Status-Active-success)]()

> **Dá»± Ã¡n Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh Linear, DLinear, vÃ  NLinear trong viá»‡c dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u VIC (Vingroup) dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­.**



[Image of Stock Market Chart generic]


## ğŸ“– Má»¥c tiÃªu (Objectives)
Dá»± Ã¡n táº­p trung giáº£i quyáº¿t bÃ i toÃ¡n dá»± bÃ¡o Time-Series tÃ i chÃ­nh vá»›i dá»¯ liá»‡u cá»• phiáº¿u VIC tá»« **2020 - 2025**. ChÃºng tÃ´i thá»±c hiá»‡n benchmark so sÃ¡nh hiá»‡u nÄƒng giá»¯a cÃ¡c biáº¿n thá»ƒ cá»§a mÃ´ hÃ¬nh Linear trÃªn cÃ¡c khung thá»i gian dá»± bÃ¡o (Prediction Horizons) khÃ¡c nhau:

* **Ngáº¯n háº¡n:** 7 ngÃ y, 30 ngÃ y.
* **Trung & DÃ i háº¡n:** 120 ngÃ y, 480 ngÃ y.

---

## ğŸ“Š Dá»¯ liá»‡u & Tiá»n xá»­ lÃ½ (Data Pipeline)

### 1. Nguá»“n dá»¯ liá»‡u
* **Dataset:** `VIC.csv`
* **Tá»•ng quan:** ~1500 báº£n ghi.
* **Features:** `time`, `open`, `high`, `low`, `close`, `volume`, `symbol`.

### 2. Quy trÃ¬nh xá»­ lÃ½ (Preprocessing)
Dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘i qua má»™t pipeline xá»­ lÃ½ nghiÃªm ngáº·t Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh cho mÃ´ hÃ¬nh há»c sÃ¢u:

1.  **Cleaning:** Chuyá»ƒn Ä‘á»•i `datetime`, sort theo thá»i gian, xá»­ lÃ½ `NaN`.
2.  **Feature Engineering:**
    * `daily_return`: Biáº¿n Ä‘á»™ng giÃ¡ hÃ ng ngÃ y.
    * `close_log`: Logarit cá»§a giÃ¡ Ä‘Ã³ng cá»­a ($\log(P)$) giÃºp chuá»—i dá»¯ liá»‡u á»•n Ä‘á»‹nh hÆ¡n, giáº£m thiá»ƒu tÃ¡c Ä‘á»™ng cá»§a biáº¿n Ä‘á»™ng máº¡nh.
3.  **Normalization:** Sá»­ dá»¥ng **StandardScaler** Ä‘á»ƒ Ä‘Æ°a dá»¯ liá»‡u vá» phÃ¢n phá»‘i chuáº©n.
4.  **Splitting:** Chia táº­p dá»¯ liá»‡u theo thá»© tá»± thá»i gian (No Shuffle):
    * ğŸŸ¢ **Train:** 70%
    * ğŸŸ¡ **Validation:** 15%
    * ğŸ”´ **Test:** 15%

---

## ğŸ§  Kiáº¿n trÃºc MÃ´ hÃ¬nh (Models)

ChÃºng tÃ´i triá»ƒn khai 3 biáº¿n thá»ƒ hiá»‡n Ä‘áº¡i cá»§a máº¡ng Linear cho Time Series:

| MÃ´ hÃ¬nh | MÃ´ táº£ | Äáº·c Ä‘iá»ƒm |
| :--- | :--- | :--- |
| **Linear** | Single Layer Perceptron | Mapping trá»±c tiáº¿p tá»« `seq_len` $\rightarrow$ `pred_len`. ÄÆ¡n giáº£n nhÆ°ng hiá»‡u quáº£. |
| **DLinear** | Decomposition Linear | PhÃ¢n rÃ£ chuá»—i thá»i gian thÃ nh **Trend** vÃ  **Remainder** trÆ°á»›c khi Ä‘Æ°a vÃ o Linear layers. |
| **NLinear** | Normalization Linear | Trá»« giÃ¡ trá»‹ cuá»‘i cÃ¹ng cá»§a input sequence Ä‘á»ƒ loáº¡i bá» non-stationarity, sau Ä‘Ã³ cá»™ng láº¡i á»Ÿ output. |

**Input Configuration:**
* **Look-back window (seq_len):** 7, 30, 120, 480 ngÃ y.
* **Prediction horizon (pred_len):** 7 ngÃ y.

---

## âš™ï¸ Huáº¥n luyá»‡n (Training Config)

QuÃ¡ trÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»™c láº­p cho tá»«ng cáº·p `Model` + `seq_len`.

* **Loss Function:** Mean Squared Error (MSE)
* **Optimizer:** Adam
* **Learning Rate:** `0.001`
* **Batch Size:** 32
* **Epochs:** 50

> ğŸ’¾ **Checkpoint:** State_dict cá»§a mÃ´ hÃ¬nh cÃ³ loss tháº¥p nháº¥t trÃªn táº­p Val Ä‘Æ°á»£c lÆ°u láº¡i dÆ°á»›i dáº¡ng `.pth`.

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng (Usage)

### 1. Load Pre-trained Model

```python
import torch
from models import Linear # Giáº£ sá»­ báº¡n Ä‘á»ƒ class model trong file models.py

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Khá»Ÿi táº¡o architecture
seq_len = 30
pred_len = 7
model = Linear(seq_len, pred_len).to(device)

# Load weights
model.load_state_dict(torch.load("checkpoints/linear_30d_state_dict.pth", map_location=device))
model.eval()
````

### 2\. Dá»± bÃ¡o giÃ¡ (Inference)

```python
import numpy as np

# 1. Láº¥y dá»¯ liá»‡u input (seq_len ngÃ y gáº§n nháº¥t) vÃ  chuáº©n hÃ³a
input_data = get_recent_data(days=30) 
x_tensor = torch.tensor(scaler.transform(input_data)).float().to(device)

# 2. Predict
with torch.no_grad():
    y_pred_log = model(x_tensor).cpu().numpy().flatten()

# 3. Inverse Scaling & Inverse Log Ä‘á»ƒ ra giÃ¡ thá»±c táº¿
y_pred_denorm = scaler.inverse_transform(y_pred_log.reshape(-1,1)).flatten()
predicted_price = np.exp(y_pred_denorm)

print(f"Dá»± Ä‘oÃ¡n giÃ¡ VIC 7 ngÃ y tá»›i: {predicted_price}")
```

-----

## ğŸ“‰ ÄÃ¡nh giÃ¡ (Evaluation)

Hiá»‡u nÄƒng mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘o lÆ°á»ng trÃªn táº­p Test báº±ng cÃ¡c metrics tiÃªu chuáº©n:

  * **MSE** (Mean Squared Error)
  * **MAE** (Mean Absolute Error)
  * **RMSE** (Root Mean Squared Error)
  * **$R^2$ Score**

### Káº¿t quáº£ sÆ¡ bá»™

  * Hiá»‡u quáº£ dá»± Ä‘oÃ¡n cÃ³ xu hÆ°á»›ng **giáº£m** khi `seq_len` tÄƒng quÃ¡ lá»›n (do nhiá»…u dá»¯ liá»‡u lá»‹ch sá»­ xa).
  * **DLinear** vÃ  **NLinear** thÆ°á»ng cho káº¿t quáº£ á»•n Ä‘á»‹nh hÆ¡n Linear thuáº§n tÃºy trong cÃ¡c giai Ä‘oáº¡n thá»‹ trÆ°á»ng biáº¿n Ä‘á»™ng máº¡nh (trend changes).

-----

## ğŸ“ Ghi chÃº (Notes)

1.  âš ï¸ **Dimension Mismatch:** Äáº£m báº£o `seq_len` khi khá»Ÿi táº¡o mÃ´ hÃ¬nh khá»›p chÃ­nh xÃ¡c vá»›i file `state_dict` Ä‘Ã£ lÆ°u.
2.  ğŸ“ˆ **Log Transformation:** Output cá»§a mÃ´ hÃ¬nh lÃ  `log_price`. Äá»«ng quÃªn dÃ¹ng hÃ m `exp()` Ä‘á»ƒ chuyá»ƒn vá» giÃ¡ VND thá»±c táº¿.

-----

### Author

Developed for Stock Prediction Research.

